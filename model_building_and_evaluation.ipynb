{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c8b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd135073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the feature-engineered data\n",
    "df = pd.read_csv('feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da4b974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>driverId</th>\n",
       "      <th>tripId</th>\n",
       "      <th>startLocation</th>\n",
       "      <th>tripDistance</th>\n",
       "      <th>tripSpeed</th>\n",
       "      <th>tripDuration</th>\n",
       "      <th>endLocation</th>\n",
       "      <th>startTime</th>\n",
       "      <th>tripFare</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>is_peak_hour</th>\n",
       "      <th>is_business_day</th>\n",
       "      <th>15min_interval</th>\n",
       "      <th>30min_interval</th>\n",
       "      <th>60min_interval</th>\n",
       "      <th>1day_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[23.075897, 72.483299]</td>\n",
       "      <td>11.8</td>\n",
       "      <td>24.97</td>\n",
       "      <td>28</td>\n",
       "      <td>[23.075855, 72.598551]</td>\n",
       "      <td>2023-01-01 18:53:00</td>\n",
       "      <td>124</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 18:45:00</td>\n",
       "      <td>2023-01-01 18:30:00</td>\n",
       "      <td>2023-01-01 18:00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[23.002, 72.550009]</td>\n",
       "      <td>8.5</td>\n",
       "      <td>15.34</td>\n",
       "      <td>33</td>\n",
       "      <td>[23.072137, 72.583952]</td>\n",
       "      <td>2023-01-01 20:39:00</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 20:30:00</td>\n",
       "      <td>2023-01-01 20:30:00</td>\n",
       "      <td>2023-01-01 20:00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[22.929988, 72.578228]</td>\n",
       "      <td>13.4</td>\n",
       "      <td>27.74</td>\n",
       "      <td>29</td>\n",
       "      <td>[23.050404, 72.578228]</td>\n",
       "      <td>2023-01-01 21:24:00</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 21:15:00</td>\n",
       "      <td>2023-01-01 21:00:00</td>\n",
       "      <td>2023-01-01 21:00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[23.029391, 72.555201]</td>\n",
       "      <td>6.3</td>\n",
       "      <td>14.47</td>\n",
       "      <td>26</td>\n",
       "      <td>[23.061703, 72.605368]</td>\n",
       "      <td>2023-01-01 21:58:00</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 21:45:00</td>\n",
       "      <td>2023-01-01 21:30:00</td>\n",
       "      <td>2023-01-01 21:00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[23.067932, 72.51617]</td>\n",
       "      <td>5.7</td>\n",
       "      <td>13.42</td>\n",
       "      <td>25</td>\n",
       "      <td>[23.103956, 72.55534]</td>\n",
       "      <td>2023-01-01 22:47:00</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-01 22:45:00</td>\n",
       "      <td>2023-01-01 22:30:00</td>\n",
       "      <td>2023-01-01 22:00:00</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[23.050932, 72.493464]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>23.06</td>\n",
       "      <td>18</td>\n",
       "      <td>[23.108462, 72.521314]</td>\n",
       "      <td>2023-01-02 18:17:00</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-02 18:15:00</td>\n",
       "      <td>2023-01-02 18:00:00</td>\n",
       "      <td>2023-01-02 18:00:00</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[22.977277, 72.530901]</td>\n",
       "      <td>7.3</td>\n",
       "      <td>19.47</td>\n",
       "      <td>22</td>\n",
       "      <td>[23.023437, 72.581065]</td>\n",
       "      <td>2023-01-02 22:59:00</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-02 22:45:00</td>\n",
       "      <td>2023-01-02 22:30:00</td>\n",
       "      <td>2023-01-02 22:00:00</td>\n",
       "      <td>2023-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[22.980471, 72.602484]</td>\n",
       "      <td>5.2</td>\n",
       "      <td>25.28</td>\n",
       "      <td>12</td>\n",
       "      <td>[23.003947, 72.64667]</td>\n",
       "      <td>2023-01-03 19:17:00</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-03 19:15:00</td>\n",
       "      <td>2023-01-03 19:00:00</td>\n",
       "      <td>2023-01-03 19:00:00</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>[23.050361, 72.532239]</td>\n",
       "      <td>8.9</td>\n",
       "      <td>22.33</td>\n",
       "      <td>24</td>\n",
       "      <td>[23.106707, 72.593512]</td>\n",
       "      <td>2023-01-03 20:23:00</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-03 20:15:00</td>\n",
       "      <td>2023-01-03 20:00:00</td>\n",
       "      <td>2023-01-03 20:00:00</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[22.974242, 72.587366]</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22.68</td>\n",
       "      <td>9</td>\n",
       "      <td>[22.989934, 72.616895]</td>\n",
       "      <td>2023-01-03 20:45:00</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-03 20:45:00</td>\n",
       "      <td>2023-01-03 20:30:00</td>\n",
       "      <td>2023-01-03 20:00:00</td>\n",
       "      <td>2023-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  driverId  tripId           startLocation  tripDistance  \\\n",
       "0           0         1       0  [23.075897, 72.483299]          11.8   \n",
       "1           1         1       1     [23.002, 72.550009]           8.5   \n",
       "2           2         1       2  [22.929988, 72.578228]          13.4   \n",
       "3           3         1       3  [23.029391, 72.555201]           6.3   \n",
       "4           4         1       4   [23.067932, 72.51617]           5.7   \n",
       "5           5         1       5  [23.050932, 72.493464]           7.0   \n",
       "6           6         1       6  [22.977277, 72.530901]           7.3   \n",
       "7           7         1       7  [22.980471, 72.602484]           5.2   \n",
       "8           8         1       8  [23.050361, 72.532239]           8.9   \n",
       "9           9         1       9  [22.974242, 72.587366]           3.5   \n",
       "\n",
       "   tripSpeed  tripDuration             endLocation            startTime  \\\n",
       "0      24.97            28  [23.075855, 72.598551]  2023-01-01 18:53:00   \n",
       "1      15.34            33  [23.072137, 72.583952]  2023-01-01 20:39:00   \n",
       "2      27.74            29  [23.050404, 72.578228]  2023-01-01 21:24:00   \n",
       "3      14.47            26  [23.061703, 72.605368]  2023-01-01 21:58:00   \n",
       "4      13.42            25   [23.103956, 72.55534]  2023-01-01 22:47:00   \n",
       "5      23.06            18  [23.108462, 72.521314]  2023-01-02 18:17:00   \n",
       "6      19.47            22  [23.023437, 72.581065]  2023-01-02 22:59:00   \n",
       "7      25.28            12   [23.003947, 72.64667]  2023-01-03 19:17:00   \n",
       "8      22.33            24  [23.106707, 72.593512]  2023-01-03 20:23:00   \n",
       "9      22.68             9  [22.989934, 72.616895]  2023-01-03 20:45:00   \n",
       "\n",
       "   tripFare  ... hour_of_day day_of_month  month  year is_peak_hour  \\\n",
       "0       124  ...          18            1      1  2023            1   \n",
       "1        91  ...          20            1      1  2023            0   \n",
       "2       140  ...          21            1      1  2023            0   \n",
       "3        69  ...          21            1      1  2023            0   \n",
       "4        63  ...          22            1      1  2023            0   \n",
       "5        76  ...          18            2      1  2023            1   \n",
       "6        79  ...          22            2      1  2023            0   \n",
       "7        58  ...          19            3      1  2023            0   \n",
       "8        95  ...          20            3      1  2023            0   \n",
       "9        41  ...          20            3      1  2023            0   \n",
       "\n",
       "  is_business_day       15min_interval       30min_interval  \\\n",
       "0               0  2023-01-01 18:45:00  2023-01-01 18:30:00   \n",
       "1               0  2023-01-01 20:30:00  2023-01-01 20:30:00   \n",
       "2               0  2023-01-01 21:15:00  2023-01-01 21:00:00   \n",
       "3               0  2023-01-01 21:45:00  2023-01-01 21:30:00   \n",
       "4               0  2023-01-01 22:45:00  2023-01-01 22:30:00   \n",
       "5               1  2023-01-02 18:15:00  2023-01-02 18:00:00   \n",
       "6               1  2023-01-02 22:45:00  2023-01-02 22:30:00   \n",
       "7               1  2023-01-03 19:15:00  2023-01-03 19:00:00   \n",
       "8               1  2023-01-03 20:15:00  2023-01-03 20:00:00   \n",
       "9               1  2023-01-03 20:45:00  2023-01-03 20:30:00   \n",
       "\n",
       "        60min_interval  1day_interval  \n",
       "0  2023-01-01 18:00:00     2023-01-01  \n",
       "1  2023-01-01 20:00:00     2023-01-01  \n",
       "2  2023-01-01 21:00:00     2023-01-01  \n",
       "3  2023-01-01 21:00:00     2023-01-01  \n",
       "4  2023-01-01 22:00:00     2023-01-01  \n",
       "5  2023-01-02 18:00:00     2023-01-02  \n",
       "6  2023-01-02 22:00:00     2023-01-02  \n",
       "7  2023-01-03 19:00:00     2023-01-03  \n",
       "8  2023-01-03 20:00:00     2023-01-03  \n",
       "9  2023-01-03 20:00:00     2023-01-03  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd35879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into chunks\n",
    "chunk_size = 1000\n",
    "chunks = [df[i:i + chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "\n",
    "# Initialize an empty DataFrame to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Create and configure the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=True, drop='first')\n",
    "\n",
    "# Process each chunk separately and concatenate the results\n",
    "for chunk in chunks:\n",
    "    # Identify columns with string values\n",
    "    string_columns = chunk.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Perform one-hot encoding only on columns with string values\n",
    "    encoded_chunk = pd.get_dummies(chunk, columns=string_columns, sparse=True, drop_first=True)\n",
    "\n",
    "    # Concatenate the encoded chunk to the result DataFrame\n",
    "    result_df = pd.concat([result_df, encoded_chunk], axis=0, ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6beed000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44718 entries, 0 to 44717\n",
      "Data columns (total 28 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       44718 non-null  int64  \n",
      " 1   driverId         44718 non-null  int64  \n",
      " 2   tripId           44718 non-null  int64  \n",
      " 3   startLocation    44718 non-null  object \n",
      " 4   tripDistance     44718 non-null  float64\n",
      " 5   tripSpeed        44718 non-null  float64\n",
      " 6   tripDuration     44718 non-null  int64  \n",
      " 7   endLocation      44718 non-null  object \n",
      " 8   startTime        44718 non-null  object \n",
      " 9   tripFare         44718 non-null  int64  \n",
      " 10  paymentType      44718 non-null  object \n",
      " 11  endTime          44718 non-null  object \n",
      " 12  latitude         44718 non-null  float64\n",
      " 13  longitude        44718 non-null  float64\n",
      " 14  latitude_bin     44718 non-null  object \n",
      " 15  longitude_bin    44718 non-null  object \n",
      " 16  time_interval    44718 non-null  object \n",
      " 17  day_of_week      44718 non-null  int64  \n",
      " 18  hour_of_day      44718 non-null  int64  \n",
      " 19  day_of_month     44718 non-null  int64  \n",
      " 20  month            44718 non-null  int64  \n",
      " 21  year             44718 non-null  int64  \n",
      " 22  is_peak_hour     44718 non-null  int64  \n",
      " 23  is_business_day  44718 non-null  int64  \n",
      " 24  15min_interval   44718 non-null  object \n",
      " 25  30min_interval   44718 non-null  object \n",
      " 26  60min_interval   44718 non-null  object \n",
      " 27  1day_interval    44718 non-null  object \n",
      "dtypes: float64(4), int64(12), object(12)\n",
      "memory usage: 9.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46124497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Unnamed: 0' from the DataFrame\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "801db792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate categorical and numerical features\n",
    "location_strings = ['startLocation', 'endLocation']\n",
    "categorical_features = ['15min_interval', '30min_interval', '60min_interval', '1day_interval']\n",
    "numerical_features = [col for col in df.columns \n",
    "                      if col not in categorical_features \n",
    "                      and col not in location_strings \n",
    "                      and col != 'tripFare']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e00d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['driverId', 'tripId', 'tripDistance', 'tripSpeed', 'tripDuration', 'startTime', 'paymentType', 'endTime', 'latitude', 'longitude', 'latitude_bin', 'longitude_bin', 'time_interval', 'day_of_week', 'hour_of_day', 'day_of_month', 'month', 'year', 'is_peak_hour', 'is_business_day']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a390e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationConverter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for column in self.columns:\n",
    "            if column in X.columns:\n",
    "                X[column + '_latitude'] = X[column].apply(lambda x: float(x[0]) if isinstance(x, list) else None)\n",
    "                X[column + '_longitude'] = X[column].apply(lambda x: float(x[1]) if isinstance(x, list) else None)\n",
    "                X = X.drop(columns=[column])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a074a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create location_converter\n",
    "# location_converter = LocationConverter(columns=['startLocation', 'endLocation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "399219f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['startLocation', 'endLocation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6b163d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformers for numerical and categorical features\n",
    "numerical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                          ('onehot', OneHotEncoder(drop='first'))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e252c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "#         ('convert', LocationConverter(columns=location_strings), location_strings)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8102e090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('num',\n",
      "                                 Pipeline(steps=[('imputer', SimpleImputer())]),\n",
      "                                 ['driverId', 'tripId', 'tripDistance',\n",
      "                                  'tripSpeed', 'tripDuration', 'startTime',\n",
      "                                  'paymentType', 'endTime', 'latitude',\n",
      "                                  'longitude', 'latitude_bin', 'longitude_bin',\n",
      "                                  'time_interval', 'day_of_week', 'hour_of_day',\n",
      "                                  'day_of_month', 'month', 'year',\n",
      "                                  'is_peak_hour', 'is_business_day']),\n",
      "                                ('cat',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('onehot',\n",
      "                                                  OneHotEncoder(drop='first'))]),\n",
      "                                 ['15min_interval', '30min_interval',\n",
      "                                  '60min_interval', '1day_interval'])])\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e598b161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['driverId', 'tripId', 'startLocation', 'tripDistance', 'tripSpeed',\n",
       "       'tripDuration', 'endLocation', 'startTime', 'tripFare', 'paymentType',\n",
       "       'endTime', 'latitude', 'longitude', 'latitude_bin', 'longitude_bin',\n",
       "       'time_interval', 'day_of_week', 'hour_of_day', 'day_of_month', 'month',\n",
       "       'year', 'is_peak_hour', 'is_business_day', '15min_interval',\n",
       "       '30min_interval', '60min_interval', '1day_interval'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cf7ca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['tripFare', 'startLocation', 'endLocation'])  # Exclude location columns\n",
    "y = df['tripFare']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef9075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4fa6def",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '2023-02-20 20:17:00'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to training and testing sets\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m      3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransform(X_test)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:743\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m--> 743\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fitted_transformers([])\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    664\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    666\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    667\u001b[0m     )\n\u001b[0;32m    668\u001b[0m )\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    671\u001b[0m         delayed(func)(\n\u001b[0;32m    672\u001b[0m             transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m    673\u001b[0m             X\u001b[38;5;241m=\u001b[39m_safe_indexing(X, column, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    674\u001b[0m             y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    675\u001b[0m             weight\u001b[38;5;241m=\u001b[39mweight,\n\u001b[0;32m    676\u001b[0m             message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    677\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx, \u001b[38;5;28mlen\u001b[39m(transformers)),\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, trans, column, weight) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(transformers, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    680\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mapply_async(batch, callback\u001b[38;5;241m=\u001b[39mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m batch()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 950\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    952\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:472\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    470\u001b[0m fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(last_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit_transform(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m last_step\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\u001b[38;5;241m.\u001b[39mtransform(Xt)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:366\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 366\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(X, in_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:327\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[0;32m    322\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[0;32m    325\u001b[0m         )\n\u001b[0;32m    326\u001b[0m     )\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '2023-02-20 20:17:00'"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to training and testing sets\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98b980",
   "metadata": {},
   "source": [
    "# Now Let's build XGBoost, DNN and ARIMA models, although it is not necessary I will be following OOPS concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04b8c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# # A custom transformer to extract features from lists\n",
    "# class ListFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         # Assuming X is a DataFrame with 'latitude_bin' and 'longitude_bin' columns\n",
    "#         X_copy = X.copy()\n",
    "        \n",
    "#         # Extract features from lists\n",
    "#         X_copy['latitude'] = X_copy['latitude_bin'].apply(lambda x: eval(x)[0] if isinstance(x, str) else x)\n",
    "#         X_copy['longitude'] = X_copy['longitude_bin'].apply(lambda x: eval(x)[1] if isinstance(x, str) else x)\n",
    "        \n",
    "#         # Drop the original 'latitude_bin' and 'longitude_bin' columns\n",
    "#         X_copy = X_copy.drop(columns=['latitude_bin', 'longitude_bin'])\n",
    "        \n",
    "#         return X_copy[['latitude', 'longitude']]\n",
    "\n",
    "# class DemandForecastingModel:\n",
    "#     def __init__(self, df):\n",
    "#         self.df = df\n",
    "#         self.features = [\n",
    "#             'day_of_week', 'hour_of_day', 'day_of_month', 'month', 'year',\n",
    "#             'latitude_bin', 'longitude_bin',\n",
    "#             'is_peak_hour', 'is_business_day',\n",
    "#             '15min_interval', '30min_interval', '60min_interval', '1day_interval'\n",
    "#         ]\n",
    "\n",
    "#     def prepare_data(self):\n",
    "#         # Drop 'Unnamed: 0' from the DataFrame\n",
    "#         self.df = self.df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#         # Separate categorical and numerical features\n",
    "#         categorical_features = ['15min_interval', '30min_interval', '60min_interval', '1day_interval']\n",
    "#         numerical_features = [col for col in self.df.columns if col not in categorical_features + ['tripFare']]\n",
    "\n",
    "#         # Create transformers for numerical and categorical features\n",
    "#         numerical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),])\n",
    "\n",
    "#         categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), \n",
    "#                                                   ('onehot', OneHotEncoder(drop='first'))])\n",
    "\n",
    "#         # Create a transformer for extracting features from lists\n",
    "#         list_feature_extractor = ListFeatureExtractor()\n",
    "\n",
    "#         # Create numeric_converter\n",
    "#         numeric_converter = StringToNumericConverter(columns=['starLocation'])\n",
    "\n",
    "#         # Use ColumnTransformer to apply transformers to specific columns\n",
    "#         preprocessor = ColumnTransformer(\n",
    "#             transformers=[\n",
    "#                 ('num', numerical_transformer, numerical_features),\n",
    "#                 ('cat', categorical_transformer, categorical_features),\n",
    "#                 ('convert', numeric_converter, ['startLocation'])  # Add this line\n",
    "#             ],\n",
    "#             remainder='passthrough'  # Include remaining columns as-is\n",
    "#         )\n",
    "\n",
    "#         # Split the data and apply preprocessing\n",
    "#         X = self.df.drop(columns=['tripFare'])\n",
    "#         y = self.df['tripFare']\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#         # Apply preprocessing to training and testing sets\n",
    "#         X_train = preprocessor.fit_transform(X_train)\n",
    "#         X_test = preprocessor.transform(X_test)\n",
    "\n",
    "#         return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "#     def train_xgboost(self, X_train, X_test, y_train, y_test):\n",
    "#         model = XGBRegressor(random_state=42)\n",
    "#         model.fit(X_train, y_train)\n",
    "#         predictions = model.predict(X_test)\n",
    "#         rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "#         print(f'XGBoost RMSE: {rmse}')\n",
    "\n",
    "#     def train_arima(self, y_train, y_test):\n",
    "#         model = ARIMA(y_train, order=(5, 1, 0))\n",
    "#         fit = model.fit()\n",
    "#         predictions = fit.forecast(steps=len(y_test))\n",
    "#         rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "#         print(f'ARIMA RMSE: {rmse}')\n",
    "\n",
    "#     def train_dnn(self, X_train, X_test, y_train, y_test):\n",
    "#         scaler = StandardScaler()\n",
    "#         X_train_scaled = scaler.fit_transform(X_train)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "#         model = MLPRegressor(random_state=42, max_iter=1000)\n",
    "#         model.fit(X_train_scaled, y_train)\n",
    "#         predictions = model.predict(X_test_scaled)\n",
    "#         rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "#         print(f'DNN RMSE: {rmse}')\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     model_instance = DemandForecastingModel(df)\n",
    "#     X_train, X_test, y_train, y_test = model_instance.prepare_data()\n",
    "\n",
    "#     model_instance.train_xgboost(X_train, X_test, y_train, y_test)\n",
    "#     model_instance.train_arima(y_train, y_test)\n",
    "#     model_instance.train_dnn(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f72294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f32c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47fec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63e13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd03e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
